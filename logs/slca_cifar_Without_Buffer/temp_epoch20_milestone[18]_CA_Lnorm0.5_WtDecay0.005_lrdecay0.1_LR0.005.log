2023-12-19 15:08:16,099 [trainer.py] => config: exps/slca_cifar100-0.8%_buffer500.json
2023-12-19 15:08:16,099 [trainer.py] => test_only: False
2023-12-19 15:08:16,099 [trainer.py] => prefix: reproduce
2023-12-19 15:08:16,099 [trainer.py] => dataset: cifar100_224
2023-12-19 15:08:16,099 [trainer.py] => num_classes: 100
2023-12-19 15:08:16,099 [trainer.py] => shuffle: False
2023-12-19 15:08:16,099 [trainer.py] => init_cls: 10
2023-12-19 15:08:16,099 [trainer.py] => increment: 10
2023-12-19 15:08:16,099 [trainer.py] => model_name: slca_cifar
2023-12-19 15:08:16,099 [trainer.py] => model_postfix: Without_Buffer
2023-12-19 15:08:16,099 [trainer.py] => convnet_type: vit-b-p16
2023-12-19 15:08:16,099 [trainer.py] => device: [device(type='cuda', index=0), device(type='cuda', index=1)]
2023-12-19 15:08:16,099 [trainer.py] => seed: 0
2023-12-19 15:08:16,099 [trainer.py] => milestones: [18]
2023-12-19 15:08:16,099 [trainer.py] => ca_with_logit_norm: 0.5
2023-12-19 15:08:16,099 [trainer.py] => lr_decay: 0.1
2023-12-19 15:08:16,099 [trainer.py] => lr: 0.005
2023-12-19 15:08:16,099 [trainer.py] => epochs: 20
2023-12-19 15:08:16,099 [trainer.py] => ca_epochs: 5
2023-12-19 15:08:16,099 [trainer.py] => weight_decay: 0.005
2023-12-19 15:08:16,099 [trainer.py] => u_batch_size: 256
2023-12-19 15:08:16,099 [trainer.py] => s_batch_size: 3
2023-12-19 15:08:16,099 [trainer.py] => multicrop: 2
2023-12-19 15:08:16,099 [trainer.py] => us_multicrop: 2
2023-12-19 15:08:16,099 [trainer.py] => subset_path: ./subsets/cifar100/0.8%_seed0.txt
2023-12-19 15:08:16,099 [trainer.py] => subset_path_cls: ./subsets/cifar100/0.8%_seed0_cls.txt
2023-12-19 15:08:16,100 [trainer.py] => buffer_size: 500
2023-12-19 15:08:16,100 [trainer.py] => run_id: 0
2023-12-19 15:08:17,686 [data_manager.py] => [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99]
2023-12-19 15:08:39,717 [trainer.py] => config: exps/slca_cifar100-0.8%_buffer500.json
2023-12-19 15:08:39,717 [trainer.py] => test_only: False
2023-12-19 15:08:39,717 [trainer.py] => prefix: reproduce
2023-12-19 15:08:39,717 [trainer.py] => dataset: cifar100_224
2023-12-19 15:08:39,717 [trainer.py] => num_classes: 100
2023-12-19 15:08:39,717 [trainer.py] => shuffle: False
2023-12-19 15:08:39,717 [trainer.py] => init_cls: 10
2023-12-19 15:08:39,717 [trainer.py] => increment: 10
2023-12-19 15:08:39,717 [trainer.py] => model_name: slca_cifar
2023-12-19 15:08:39,717 [trainer.py] => model_postfix: Without_Buffer
2023-12-19 15:08:39,717 [trainer.py] => convnet_type: vit-b-p16
2023-12-19 15:08:39,717 [trainer.py] => device: [device(type='cuda', index=0), device(type='cuda', index=1)]
2023-12-19 15:08:39,718 [trainer.py] => seed: 0
2023-12-19 15:08:39,718 [trainer.py] => milestones: [18]
2023-12-19 15:08:39,718 [trainer.py] => ca_with_logit_norm: 0.5
2023-12-19 15:08:39,718 [trainer.py] => lr_decay: 0.1
2023-12-19 15:08:39,718 [trainer.py] => lr: 0.005
2023-12-19 15:08:39,718 [trainer.py] => epochs: 20
2023-12-19 15:08:39,718 [trainer.py] => ca_epochs: 5
2023-12-19 15:08:39,718 [trainer.py] => weight_decay: 0.005
2023-12-19 15:08:39,718 [trainer.py] => u_batch_size: 256
2023-12-19 15:08:39,718 [trainer.py] => s_batch_size: 3
2023-12-19 15:08:39,718 [trainer.py] => multicrop: 2
2023-12-19 15:08:39,718 [trainer.py] => us_multicrop: 2
2023-12-19 15:08:39,718 [trainer.py] => subset_path: ./subsets/cifar100/0.8%_seed0.txt
2023-12-19 15:08:39,718 [trainer.py] => subset_path_cls: ./subsets/cifar100/0.8%_seed0_cls.txt
2023-12-19 15:08:39,718 [trainer.py] => buffer_size: 500
2023-12-19 15:08:39,718 [trainer.py] => run_id: 0
2023-12-19 15:08:41,304 [data_manager.py] => [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99]
2023-12-19 15:08:43,370 [trainer.py] => All params: 85798656
2023-12-19 15:08:43,370 [trainer.py] => Trainable params: 85798656
2023-12-19 15:08:43,371 [slca.py] => Learning on 0-10
2023-12-19 15:10:57,047 [trainer.py] => config: exps/slca_cifar100-0.8%_buffer500.json
2023-12-19 15:10:57,047 [trainer.py] => test_only: False
2023-12-19 15:10:57,047 [trainer.py] => prefix: reproduce
2023-12-19 15:10:57,047 [trainer.py] => dataset: cifar100_224
2023-12-19 15:10:57,047 [trainer.py] => num_classes: 100
2023-12-19 15:10:57,047 [trainer.py] => shuffle: False
2023-12-19 15:10:57,047 [trainer.py] => init_cls: 10
2023-12-19 15:10:57,047 [trainer.py] => increment: 10
2023-12-19 15:10:57,047 [trainer.py] => model_name: slca_cifar
2023-12-19 15:10:57,047 [trainer.py] => model_postfix: Without_Buffer
2023-12-19 15:10:57,047 [trainer.py] => convnet_type: vit-b-p16
2023-12-19 15:10:57,047 [trainer.py] => device: [device(type='cuda', index=0), device(type='cuda', index=1)]
2023-12-19 15:10:57,047 [trainer.py] => seed: 0
2023-12-19 15:10:57,047 [trainer.py] => milestones: [18]
2023-12-19 15:10:57,048 [trainer.py] => ca_with_logit_norm: 0.5
2023-12-19 15:10:57,048 [trainer.py] => lr_decay: 0.1
2023-12-19 15:10:57,048 [trainer.py] => lr: 0.005
2023-12-19 15:10:57,048 [trainer.py] => epochs: 20
2023-12-19 15:10:57,048 [trainer.py] => ca_epochs: 5
2023-12-19 15:10:57,048 [trainer.py] => weight_decay: 0.005
2023-12-19 15:10:57,048 [trainer.py] => u_batch_size: 256
2023-12-19 15:10:57,048 [trainer.py] => s_batch_size: 3
2023-12-19 15:10:57,048 [trainer.py] => multicrop: 2
2023-12-19 15:10:57,048 [trainer.py] => us_multicrop: 2
2023-12-19 15:10:57,048 [trainer.py] => subset_path: ./subsets/cifar100/0.8%_seed0.txt
2023-12-19 15:10:57,048 [trainer.py] => subset_path_cls: ./subsets/cifar100/0.8%_seed0_cls.txt
2023-12-19 15:10:57,048 [trainer.py] => buffer_size: 500
2023-12-19 15:10:57,048 [trainer.py] => run_id: 0
2023-12-19 15:10:58,636 [data_manager.py] => [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99]
2023-12-19 15:11:00,702 [trainer.py] => All params: 85798656
2023-12-19 15:11:00,703 [trainer.py] => Trainable params: 85798656
2023-12-19 15:11:00,704 [slca.py] => Learning on 0-10
2023-12-19 15:11:37,135 [trainer.py] => config: exps/slca_cifar100-0.8%_buffer500.json
2023-12-19 15:11:37,135 [trainer.py] => test_only: False
2023-12-19 15:11:37,136 [trainer.py] => prefix: reproduce
2023-12-19 15:11:37,136 [trainer.py] => dataset: cifar100_224
2023-12-19 15:11:37,136 [trainer.py] => num_classes: 100
2023-12-19 15:11:37,136 [trainer.py] => shuffle: False
2023-12-19 15:11:37,136 [trainer.py] => init_cls: 10
2023-12-19 15:11:37,136 [trainer.py] => increment: 10
2023-12-19 15:11:37,136 [trainer.py] => model_name: slca_cifar
2023-12-19 15:11:37,136 [trainer.py] => model_postfix: Without_Buffer
2023-12-19 15:11:37,136 [trainer.py] => convnet_type: vit-b-p16
2023-12-19 15:11:37,136 [trainer.py] => device: [device(type='cuda', index=0), device(type='cuda', index=1)]
2023-12-19 15:11:37,136 [trainer.py] => seed: 0
2023-12-19 15:11:37,136 [trainer.py] => milestones: [18]
2023-12-19 15:11:37,136 [trainer.py] => ca_with_logit_norm: 0.5
2023-12-19 15:11:37,136 [trainer.py] => lr_decay: 0.1
2023-12-19 15:11:37,136 [trainer.py] => lr: 0.005
2023-12-19 15:11:37,136 [trainer.py] => epochs: 20
2023-12-19 15:11:37,136 [trainer.py] => ca_epochs: 5
2023-12-19 15:11:37,136 [trainer.py] => weight_decay: 0.005
2023-12-19 15:11:37,136 [trainer.py] => u_batch_size: 256
2023-12-19 15:11:37,136 [trainer.py] => s_batch_size: 3
2023-12-19 15:11:37,136 [trainer.py] => multicrop: 2
2023-12-19 15:11:37,136 [trainer.py] => us_multicrop: 2
2023-12-19 15:11:37,136 [trainer.py] => subset_path: ./subsets/cifar100/0.8%_seed0.txt
2023-12-19 15:11:37,136 [trainer.py] => subset_path_cls: ./subsets/cifar100/0.8%_seed0_cls.txt
2023-12-19 15:11:37,136 [trainer.py] => buffer_size: 500
2023-12-19 15:11:37,136 [trainer.py] => run_id: 0
2023-12-19 15:11:38,724 [data_manager.py] => [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99]
2023-12-19 15:11:40,809 [trainer.py] => All params: 85798656
2023-12-19 15:11:40,810 [trainer.py] => Trainable params: 85798656
2023-12-19 15:11:40,810 [slca.py] => Learning on 0-10
2023-12-19 15:11:51,453 [slca.py] => Task 0, Epoch 1/20 => Loss 2.357
2023-12-19 15:11:52,697 [slca.py] => Task 0, Epoch 2/20 => Loss 2.382
2023-12-19 15:11:53,902 [slca.py] => Task 0, Epoch 3/20 => Loss 2.274
2023-12-19 15:11:55,110 [slca.py] => Task 0, Epoch 4/20 => Loss 2.058
2023-12-19 15:12:00,257 [slca.py] => Task 0, Epoch 5/20 => Loss 1.883, Train_accy 57.500, Test_accy 39.960
2023-12-19 15:12:01,457 [slca.py] => Task 0, Epoch 6/20 => Loss 1.699
2023-12-19 15:12:02,657 [slca.py] => Task 0, Epoch 7/20 => Loss 1.405
2023-12-19 15:12:03,843 [slca.py] => Task 0, Epoch 8/20 => Loss 1.355
2023-12-19 15:12:05,087 [slca.py] => Task 0, Epoch 9/20 => Loss 1.156
2023-12-19 15:12:10,108 [slca.py] => Task 0, Epoch 10/20 => Loss 0.952, Train_accy 92.500, Test_accy 69.870
2023-12-19 15:12:11,302 [slca.py] => Task 0, Epoch 11/20 => Loss 0.776
2023-12-19 15:12:12,550 [slca.py] => Task 0, Epoch 12/20 => Loss 0.795
2023-12-19 15:12:13,766 [slca.py] => Task 0, Epoch 13/20 => Loss 0.578
2023-12-19 15:12:14,968 [slca.py] => Task 0, Epoch 14/20 => Loss 0.460
2023-12-19 15:12:20,041 [slca.py] => Task 0, Epoch 15/20 => Loss 0.485, Train_accy 95.000, Test_accy 80.920
2023-12-19 15:12:21,320 [slca.py] => Task 0, Epoch 16/20 => Loss 0.334
2023-12-19 15:12:22,560 [slca.py] => Task 0, Epoch 17/20 => Loss 0.356
2023-12-19 15:12:23,787 [slca.py] => Task 0, Epoch 18/20 => Loss 0.295
2023-12-19 15:12:25,032 [slca.py] => Task 0, Epoch 19/20 => Loss 0.215
2023-12-19 15:12:30,026 [slca.py] => Task 0, Epoch 20/20 => Loss 0.298, Train_accy 97.500, Test_accy 83.930
